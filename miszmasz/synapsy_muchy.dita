<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="synapsy_muchy">
    <title>Synapsy muchy</title>
    <body>
        <p><xref
                href="https://news.berkeley.edu/2019/01/17/thanks-to-rapid-3d-imaging-anyone-can-tour-the-fly-brain/?fbclid=IwAR2lYlS41zI9Pt8umFguy3nah_v3axvwo1imPvS9yz9qyTIZ60L9ftgyPDE"
                format="html" scope="external"/></p>
        <p>O tutaj wypowiadają się nobliści. </p>
        <p> Hmm i nawet bardzo ciekawe. Mmm, i przy okazji nie jest antypolskie - ale niespodzianka!
            Spodziewałem się, że gdzieś tam będzie napisane o tym, że "Gość w dom, Bóg w dom" to
            Polski wymysł, ale miło się zawiodłem. Nikt tu też nie mówi, że jest Polką, a czuje się
            Ukrainką. Nie, nie widze chazarskiej socjotechniki. Ale miło. Mózg odpoczywa.</p>
        <p> To mówicie, że synapsy muchy zrobili w 3D? Fajnie, technologia idzie do przodu. Nowa
            kombinatoryka pewnie się ukarze w sieciach neuronowych, jakieś ciekawostki. Ciekawe,
            ciekawe. Machine Learning wybiera sobie jakąś sekwencję, a potem ją tłucze. A co jeśli
            wziąc strukturę neuronową, która zapamięta, a program określi, co zapamiętała, na
            podstawie, jak to zrobiła? Trzeba by doszukać się jakiejś właściwości, nagrać i odwrócić
            logikę, rozbić ją na dwie wartości i 3cia to znaczenie. Wtedy powstałe moduły mogą być
            predysponowane pod określone zachowania. Eeee... pierdolenie.</p>
    </body>
</topic>
